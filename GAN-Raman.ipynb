{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import utils\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import pathlib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "debug = True\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) \n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e438e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "file_path_spectra = cwd / '..'  /  '..'  / 'datasets' / 'RiverD' / 'RamanData_pc.xlsx'\n",
    "file_path_classes = cwd / '..'  /  '..'  / 'datasets' / 'RiverD' / 'RamanMetaData.xlsx'\n",
    "try:\n",
    "    df_spectra = pd.read_excel(file_path_spectra)\n",
    "    df_classes = pd.read_excel(file_path_classes, sheet_name=\"class\", header=None)\n",
    "except FileNotFoundError:\n",
    "    print(\"File could not be found\")\n",
    "except Exception as e:\n",
    "    print(f\"An error ocurred reading file, Exception: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e789d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RamanSpectraGANDataset(Dataset):\n",
    "    def __init__(self, dataframe_X, dataframe_y, transforms=None):\n",
    "        self.spectra = dataframe_X\n",
    "        self.targets = dataframe_y\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.spectra.columns = self.spectra.columns.astype(str)\n",
    "        self.spectrum_scaler = MinMaxScaler()\n",
    "        self.normalized_spectra = self.spectrum_scaler.fit_transform(self.spectra).astype(np.float32)\n",
    "\n",
    "        self.label_encoders = []\n",
    "        # Encodes the targets\n",
    "        le = LabelEncoder()\n",
    "        self.encoded_targets = le.fit_transform(self.targets).astype(np.int32)        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.normalized_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.normalized_spectra[idx]), torch.tensor(self.encoded_targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92031aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(spectrum_series: pd.Series):\n",
    "    \n",
    "    y_values = spectrum_series    \n",
    "    x_values = range(len(y_values))\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(x_values, y_values)\n",
    "    \n",
    "    plt.title(\"Raman Spectrum\")\n",
    "    plt.xlabel(\"Feature Index (Pixel)\")\n",
    "    plt.ylabel(\"Intensity (Normalized)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01923d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(epoch, dim, features, generator, real_samples, real_labels, num_samples=50):\n",
    "   \n",
    "    generator.eval()  \n",
    "    \n",
    "    real_to_plot = real_samples[:num_samples, :].cpu().numpy().squeeze()\n",
    "    labels = real_labels[:num_samples]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_samples, dim).to(device)\n",
    "        fake_to_plot = generator(noise,labels)[:num_samples, :].cpu().numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    fig.suptitle(f'Epoch {epoch+1} - Real vs. Generated Samples', fontsize=16)\n",
    "    x_axis = np.arange(features-1)\n",
    "\n",
    "    ax1.set_title(\"Real Samples\")\n",
    "    for i in range(num_samples):\n",
    "        ax1.plot(x_axis, real_to_plot[i], alpha=0.7, label=f'Real {i+1}')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_title(\"Generated Samples\")\n",
    "    for i in range(num_samples):\n",
    "        ax2.plot(x_axis, fake_to_plot[i], alpha=0.7, label=f'Fake {i+1}')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    generator.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cfd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_generated_samples(epoch, output_folder, dim, generator, labels, num_samples=50, device='cpu'):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    generator.eval()\n",
    "    \n",
    "    current_labels = labels[:num_samples]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_samples, dim).to(device)\n",
    "        generated_data = generator(noise, current_labels).cpu().numpy().squeeze()\n",
    "        \n",
    "        if isinstance(current_labels, torch.Tensor):\n",
    "            current_labels_np = current_labels.cpu().numpy()\n",
    "            if len(current_labels_np.shape) > 1 and current_labels_np.shape[1] > 1:\n",
    "                current_labels_np = np.argmax(current_labels_np, axis=1)\n",
    "        else:\n",
    "            current_labels_np = current_labels\n",
    "\n",
    "    df = pd.DataFrame(generated_data)\n",
    "    df.columns = [f'feat_{i}' for i in range(df.shape[1])]\n",
    "    df.insert(0, 'label', current_labels_np)\n",
    "\n",
    "    filename = f\"epoch_{epoch+1:03d}_generated.csv\"\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    \n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Epoch {epoch+1}: Saved {num_samples} generated samples to {file_path}\")\n",
    "\n",
    "    generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "df_classes.columns = df_spectra.columns\n",
    "df_spectra = df_spectra.T\n",
    "df_classes = df_classes.T\n",
    "df_combined = pd.concat([df_spectra, df_classes], ignore_index=True, axis=1)\n",
    "dataset_X = df_combined.iloc[:, :-1]\n",
    "dataset_y = df_combined.iloc[:, -1]\n",
    "dataset = RamanSpectraGANDataset(dataset_X, dataset_y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de24091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels=2, seq_len=700, embed_dim = 50, n_classes=1):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embed = nn.Embedding(n_classes, embed_dim)\n",
    "        self.embed_fc = utils.spectral_norm(nn.Linear(embed_dim, seq_len)) \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 32, kernel_size=6, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv1d(32, 64, kernel_size=6, stride=2, padding=2, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv1d(64, 128, kernel_size=6, stride=2, padding=2, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv1d(128, 256, kernel_size=6, stride=2, padding=2, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Flatten()           \n",
    "            \n",
    "        )\n",
    "        encoder_output_dim = 5376\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(encoder_output_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        y_embed = self.embed(y).squeeze(1)\n",
    "        y_embed = self.embed_fc(y_embed).view(-1, self.seq_len)\n",
    "        combined_input = torch.cat([x, y_embed], dim=1)\n",
    "        combined_input = combined_input.view(-1, 2, self.seq_len)\n",
    "        x = self.main(combined_input)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels=1, seq_len=700, z_dim=123, embed_dim = 5, n_classes=1):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.init_seq_len = seq_len // 16\n",
    "        self.embed = nn.Embedding(n_classes, embed_dim)\n",
    "        self.fc = nn.Linear(z_dim + embed_dim, 256 * self.init_seq_len)\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Unflatten(1, (256, self.init_seq_len)),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=6, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=6, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=6, stride=2, padding=2, output_padding=0),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),            \n",
    "            nn.ConvTranspose1d(32, input_channels, kernel_size=2, stride=2, padding=0, output_padding=0),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "       \n",
    "\n",
    "    def forward(self, x, y):\n",
    "        y_embed = self.embed(y)\n",
    "        combined_input = torch.cat([x, y_embed], dim=1)\n",
    "        x = self.fc(combined_input)\n",
    "        x = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "g_lr = 0.00009\n",
    "d_lr = 0.00005\n",
    "noise_size = 123\n",
    "LOG_INTERVAL = 50    \n",
    "PLOT_INTERVAL = 10    \n",
    "\n",
    "fixed_noise = torch.randn(64, noise_size, device=device)\n",
    "fixed_real_samples, fixed_real_labels = next(iter(dataloader))\n",
    "fixed_real_samples = fixed_real_samples.to(device)\n",
    "fixed_real_labels = fixed_real_labels.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=d_lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=g_lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4dddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "D_accuracies = []\n",
    "iters = 0\n",
    "num_epochs =  2000 #to test\n",
    "\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    netD.train()\n",
    "    for i, (spectra, labels) in enumerate(dataloader):        \n",
    "        spectra = spectra.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = spectra.size(0)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        real_output = netD(spectra, labels) \n",
    "\n",
    "        d_loss_real = criterion(real_output, real_labels)\n",
    "        real_acc = ((real_output > 0.5).float() == real_labels).float().mean()\n",
    "       \n",
    "        noise = torch.randn(batch_size, noise_size, device=device)\n",
    "        fake_spectra = netG(noise, labels).squeeze()\n",
    "        \n",
    "        fake_output = netD(fake_spectra.detach(), labels)        \n",
    "        d_loss_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "        fake_acc = (fake_output < 0.5).float().mean()\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        \n",
    "        optimizerD.step()\n",
    "\n",
    "        d_accuracy = (real_acc + fake_acc) / 2\n",
    "\n",
    "        optimizerG.zero_grad()\n",
    "        fake_spectra_for_g = netG(noise,labels).squeeze()\n",
    "        output = netD(fake_spectra_for_g, labels)\n",
    "\n",
    "        g_loss = criterion(output, real_labels)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if (i + 1) % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                f\"[Epoch {epoch+1}/{num_epochs}] [Batch {i+1}/{len(dataloader)}] \"\n",
    "                f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}] \"\n",
    "                f\"[D Acc: {d_accuracy.item():.2%}]\"\n",
    "            )\n",
    "            D_losses.append(d_loss.item())\n",
    "            G_losses.append(g_loss.item())\n",
    "            D_accuracies.append(d_accuracy.item())\n",
    "        \n",
    "    if (epoch + 1) % PLOT_INTERVAL == 0:\n",
    "        print(f\"--- Generating plot for epoch {epoch+1} ---\")\n",
    "        plot_samples(epoch=epoch, generator=netG, real_samples=fixed_real_samples, real_labels=fixed_real_labels ,dim=noise_size, features=701)\n",
    "\n",
    "\n",
    "print(\"--- Training Finished ---\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
